{"cells":[{"cell_type":"markdown","source":["## Leer archivo de datos raw-flight-data.csv y crear el data schema"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\n\n#create session\nappName = \"Pre-procesamiento de datos en Spark\"\nspark = SparkSession \\\n    .builder \\\n    .appName(appName) \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()\n\nflightSchema = StructType([\n  StructField(\"DayofMonth\", IntegerType(), False),\n  StructField(\"DayOfWeek\", IntegerType(), False),\n  StructField(\"Carrier\", StringType(), False),\n  StructField(\"OriginAirportID\", IntegerType(), False),\n  StructField(\"DestAirportID\", IntegerType(), False),\n  StructField(\"DepDelay\", IntegerType(), False),\n  StructField(\"ArrDelay\", IntegerType(), False),\n])\n\nflights = spark.read.csv('/FileStore/tables/raw_flight_data-eb9f8.csv', \n                         schema=flightSchema, header=True)\nflights.show(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+---------+-------+---------------+-------------+--------+--------+\nDayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n+----------+---------+-------+---------------+-------------+--------+--------+\n        19|        5|     DL|          11433|        13303|      -3|       1|\n        19|        5|     DL|          14869|        12478|       0|      -8|\n+----------+---------+-------+---------------+-------------+--------+--------+\nonly showing top 2 rows\n\n</div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["## Cargamos el archivo airports.csv en el dataframe airports"],"metadata":{}},{"cell_type":"code","source":["airportSchema = StructType([\n  StructField(\"airport_id\", IntegerType(), False),\n  StructField(\"city\", StringType(), False),\n  StructField(\"state\", StringType(), False),\n  StructField(\"name\", StringType(), False),\n])\n\nairports = spark.read.csv('dataset/airports.csv', header=True, \n                          schema=airportSchema)\nairports.show(2)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["## Cruzamos los 2 dataframes (flights and airports), y mostramos cuantos vuelos hay desde cada ciudad"],"metadata":{}},{"cell_type":"code","source":["flightsByOrigin = flights.join(airports,\n                               flights.OriginAirportID == \n                               airports.airport_id).groupBy(\"city\").count()\nflightsByOrigin.show(10)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Manipulando data duplicada\nEliminar data duplicada y calcular cuantos registros duplicados existen"],"metadata":{}},{"cell_type":"code","source":["#Cantidad original de registros\nn1 = flights.count()\nprint(\"Número original de registros: \", n1)\n\n#Cuenta los registros luego de eliminar la data duplicada\nn2 = flights.dropDuplicates().count()\nprint(\"Número de registros luego de eliminar la data duplicadad: \", n2)\n\nn3 = n1 - n2\nprint(\"Número de registros duplicados eliminados: \", n3)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Especificamos el criterio para registros duplicados"],"metadata":{}},{"cell_type":"code","source":["df = spark.createDataFrame([(\"Rony\",27, 168), \n                            (\"Rony\",15, 165), \n                            (\"Rony\",27, 168)], \n                           [\"name\",\"age\",\"height\"])\ndf.show()\ndf.dropDuplicates().show()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Eliminamos duplicados por un solo campo"],"metadata":{}},{"cell_type":"code","source":["df.dropDuplicates(['name']).show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["## Manipulando data en missing"],"metadata":{}},{"cell_type":"markdown","source":["1. Elimina la fila si al menos existe una columna en missing"],"metadata":{}},{"cell_type":"code","source":["flightsNoMissingValue = flights.dropDuplicates().dropna(\n    how=\"any\", subset=[\"ArrDelay\", \"DepDelay\"])\n# usar how=\"all\" si se busca que todas las columnas estén en missing\n# usar how=\"any\" si se busca que al menos una columna esté en missins\n\nnumberOfMissingValueAny = n1 - flightsNoMissingValue.count()\n\nprint(\"Número de filas con al menos un valor en missing: \", numberOfMissingValueAny)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["2. Completar la data en missing usando el valor del Promedio de la columna respectiva"],"metadata":{}},{"cell_type":"code","source":["#Obtener el valor promedio\nmeanArrDelay = flights.groupBy().avg(\"ArrDelay\").take(1)[0][0]\n\nprint(\"Promedio de ArrDelay: \", meanArrDelay)\n\nmeanDepDelay = flights.groupBy().avg(\"DepDelay\").take(1)[0][0]\n\nprint(\"Promedio de DepDelay: \", meanDepDelay)\n\n#Eliminar data duplicada y completarla con el valor promedio del campo\nflightsCleanData=flights.fillna(\n    {'ArrDelay': meanArrDelay, 'DepDelay': meanDepDelay})\n\n#El promedio de ArrDelay se mantiene\nflights.groupBy().avg(\"ArrDelay\").show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["## Explorar las estadísticas de nuestra data"],"metadata":{}},{"cell_type":"code","source":["flightsCleanData.describe('DepDelay','ArrDelay').show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["También podemos calcular la correlación entre dos variables para sabes si una variable está relacionada a la otra"],"metadata":{}},{"cell_type":"code","source":["correlation = flightsCleanData.corr('DepDelay', 'ArrDelay')\nprint(\"correlation between departure delay and arrival delay: \", \n      correlation)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.1","nbconvert_exporter":"python","file_extension":".py"},"name":"03 Pre-Procesamiento de Data en Spark","notebookId":2460219875128139},"nbformat":4,"nbformat_minor":0}
